#!/usr/bin/env python3
"""
RSP ë…¼ë¬¸ ì¶”ì²œ ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ ì ê²€ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import psycopg2
import requests
import json
from datetime import datetime

def check_postgresql_status():
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸"""
    print("=" * 60)
    print("1. PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸")
    print("=" * 60)

    # ì‹œë„í•  ë¹„ë°€ë²ˆí˜¸ ëª©ë¡
    passwords = ["ssafy", "postgres123", "postgres", "SecurePostgres123!", ""]
    databases = ["rsp_db", "papers_db", "postgres"]

    conn = None
    for db in databases:
        for password in passwords:
            try:
                # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„
                conn = psycopg2.connect(
                    host="localhost",
                    database=db,
                    user="postgres",
                    password=password
                )
                print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ: {db} (password: {'***' if password else 'none'})")
                break
            except Exception as e:
                continue
        if conn:
            break

    if not conn:
        print("âŒ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„ ì‹¤íŒ¨")
        return None

    try:
        cursor = conn.cursor()

        # ì „ì²´ ë…¼ë¬¸ ìˆ˜
        cursor.execute("SELECT COUNT(*) FROM papers")
        total_papers = cursor.fetchone()[0]
        print(f"ì „ì²´ ë…¼ë¬¸ ìˆ˜: {total_papers:,}")

        # ì„ë² ë”© ìƒì„±ëœ ë…¼ë¬¸ ìˆ˜
        cursor.execute("SELECT COUNT(*) FROM papers WHERE embedding IS NOT NULL")
        papers_with_embeddings = cursor.fetchone()[0]
        print(f"ì„ë² ë”© ìƒì„±ëœ ë…¼ë¬¸ ìˆ˜: {papers_with_embeddings:,}")

        # GROBID ì²˜ë¦¬ëœ ë…¼ë¬¸ ìˆ˜ (grobid_dataê°€ ìˆëŠ” ë…¼ë¬¸)
        cursor.execute("SELECT COUNT(*) FROM papers WHERE grobid_data IS NOT NULL")
        grobid_processed = cursor.fetchone()[0]
        print(f"GROBID ì²˜ë¦¬ëœ ë…¼ë¬¸ ìˆ˜: {grobid_processed:,}")

        # í‚¤ì›Œë“œ ì¶”ì¶œëœ ë…¼ë¬¸ ìˆ˜
        cursor.execute("SELECT COUNT(*) FROM papers WHERE keywords IS NOT NULL")
        papers_with_keywords = cursor.fetchone()[0]
        print(f"í‚¤ì›Œë“œ ì¶”ì¶œëœ ë…¼ë¬¸ ìˆ˜: {papers_with_keywords:,}")

        # PDF íŒŒì¼ì´ ìˆëŠ” ë…¼ë¬¸ ìˆ˜
        cursor.execute("SELECT COUNT(*) FROM papers WHERE pdf_url IS NOT NULL")
        papers_with_pdf = cursor.fetchone()[0]
        print(f"PDF íŒŒì¼ì´ ìˆëŠ” ë…¼ë¬¸ ìˆ˜: {papers_with_pdf:,}")

        # Full textê°€ ìˆëŠ” ë…¼ë¬¸ ìˆ˜
        cursor.execute("SELECT COUNT(*) FROM papers WHERE full_text IS NOT NULL AND full_text != ''")
        papers_with_fulltext = cursor.fetchone()[0]
        print(f"ì „ë¬¸ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ë…¼ë¬¸ ìˆ˜: {papers_with_fulltext:,}")

        # GROBID ìƒíƒœë³„ ë…¼ë¬¸ ìˆ˜
        cursor.execute("SELECT grobid_status, COUNT(*) FROM papers WHERE grobid_status IS NOT NULL GROUP BY grobid_status")
        grobid_status_counts = cursor.fetchall()
        if grobid_status_counts:
            print("\nGROBID ìƒíƒœë³„ ë…¼ë¬¸ ìˆ˜:")
            for status, count in grobid_status_counts:
                print(f"  {status}: {count:,}")

        # ë…¼ë¬¸ ì„ë² ë”© ê´€ë ¨ í†µê³„
        cursor.execute("SELECT COUNT(*) FROM paper_embeddings")
        embedding_table_count = cursor.fetchone()[0]
        print(f"paper_embeddings í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜: {embedding_table_count:,}")

        # ìµœê·¼ ì¶”ê°€ëœ ë…¼ë¬¸ (ìµœê·¼ 7ì¼)
        cursor.execute("""
            SELECT COUNT(*) FROM papers
            WHERE created_at >= NOW() - INTERVAL '7 days'
        """)
        recent_papers = cursor.fetchone()[0]
        print(f"ìµœê·¼ 7ì¼ê°„ ì¶”ê°€ëœ ë…¼ë¬¸ ìˆ˜: {recent_papers:,}")

        # ì²˜ë¦¬ ì™„ë£Œ ë¹„ìœ¨ ê³„ì‚°
        if total_papers > 0:
            embedding_ratio = (papers_with_embeddings / total_papers) * 100
            grobid_ratio = (grobid_processed / total_papers) * 100
            keyword_ratio = (papers_with_keywords / total_papers) * 100

            print(f"\nì²˜ë¦¬ ì™„ë£Œ ë¹„ìœ¨:")
            print(f"  ì„ë² ë”© ìƒì„±: {embedding_ratio:.1f}%")
            print(f"  GROBID ì²˜ë¦¬: {grobid_ratio:.1f}%")
            print(f"  í‚¤ì›Œë“œ ì¶”ì¶œ: {keyword_ratio:.1f}%")

        cursor.close()
        conn.close()

        return {
            'total_papers': total_papers,
            'papers_with_embeddings': papers_with_embeddings,
            'grobid_processed': grobid_processed,
            'papers_with_keywords': papers_with_keywords,
            'papers_with_pdf': papers_with_pdf,
            'papers_with_fulltext': papers_with_fulltext,
            'embedding_table_count': embedding_table_count,
            'recent_papers': recent_papers
        }

    except Exception as e:
        print(f"PostgreSQL ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

def check_hbase_status():
    """HBase ìœ ì‚¬ë„ ë°ì´í„° ìƒíƒœ í™•ì¸"""
    print("\n" + "=" * 60)
    print("2. HBase ìœ ì‚¬ë„ ë°ì´í„° ìƒíƒœ í™•ì¸")
    print("=" * 60)

    try:
        # HBase REST APIë¥¼ í†µí•œ í…Œì´ë¸” ìŠ¤ìº”
        hbase_url = "http://localhost:8080"

        # paper_similarities í…Œì´ë¸” ì¡´ì¬ í™•ì¸
        tables_url = f"{hbase_url}/tables"
        response = requests.get(tables_url, headers={'Accept': 'application/json'})

        if response.status_code == 200:
            tables = response.json().get('tables', [])
            similarity_table_exists = 'paper_similarities' in [table['name'] for table in tables]
            print(f"paper_similarities í…Œì´ë¸” ì¡´ì¬: {similarity_table_exists}")

            if similarity_table_exists:
                # í…Œì´ë¸” í–‰ ìˆ˜ í™•ì¸ (ìƒ˜í”Œë§)
                scan_url = f"{hbase_url}/paper_similarities/*"
                scan_response = requests.get(scan_url, headers={'Accept': 'application/json'})

                if scan_response.status_code == 200:
                    scan_data = scan_response.json()
                    row_count = len(scan_data.get('Row', []))
                    print(f"ìœ ì‚¬ë„ ë°ì´í„° í–‰ ìˆ˜ (ìƒ˜í”Œ): {row_count}")
                else:
                    print("ìœ ì‚¬ë„ ë°ì´í„° ìŠ¤ìº” ì‹¤íŒ¨")

        else:
            print(f"HBase REST API ì—°ê²° ì‹¤íŒ¨: {response.status_code}")

    except Exception as e:
        print(f"HBase ì—°ê²° ì˜¤ë¥˜: {e}")

def check_opensearch_status():
    """OpenSearch ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸"""
    print("\n" + "=" * 60)
    print("3. OpenSearch ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸")
    print("=" * 60)

    try:
        opensearch_url = "http://localhost:9200"

        # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
        health_response = requests.get(f"{opensearch_url}/_cluster/health")
        if health_response.status_code == 200:
            health_data = health_response.json()
            print(f"í´ëŸ¬ìŠ¤í„° ìƒíƒœ: {health_data.get('status', 'unknown')}")
            print(f"ë…¸ë“œ ìˆ˜: {health_data.get('number_of_nodes', 0)}")

        # ì¸ë±ìŠ¤ ëª©ë¡ í™•ì¸
        indices_response = requests.get(f"{opensearch_url}/_cat/indices?format=json")
        if indices_response.status_code == 200:
            indices = indices_response.json()
            paper_indices = [idx for idx in indices if 'paper' in idx.get('index', '')]

            print(f"\në…¼ë¬¸ ê´€ë ¨ ì¸ë±ìŠ¤:")
            for idx in paper_indices:
                index_name = idx.get('index', '')
                doc_count = idx.get('docs.count', '0')
                print(f"  {index_name}: {doc_count} ë¬¸ì„œ")

        # papers ì¸ë±ìŠ¤ ìƒì„¸ ì •ë³´
        try:
            papers_stats = requests.get(f"{opensearch_url}/papers/_stats")
            if papers_stats.status_code == 200:
                stats_data = papers_stats.json()
                total_docs = stats_data['_all']['total']['docs']['count']
                print(f"\npapers ì¸ë±ìŠ¤ ì´ ë¬¸ì„œ ìˆ˜: {total_docs:,}")
        except:
            print("papers ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨")

    except Exception as e:
        print(f"OpenSearch ì—°ê²° ì˜¤ë¥˜: {e}")

def check_grobid_service():
    """GROBID ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    print("\n" + "=" * 60)
    print("4. GROBID ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸")
    print("=" * 60)

    try:
        grobid_url = "http://localhost:8070"

        # GROBID ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        response = requests.get(f"{grobid_url}/api/isalive", timeout=5)
        if response.status_code == 200:
            print("GROBID ì„œë¹„ìŠ¤: ì •ìƒ ì‘ë™")

            # ë²„ì „ ì •ë³´ í™•ì¸
            version_response = requests.get(f"{grobid_url}/api/version", timeout=5)
            if version_response.status_code == 200:
                print(f"GROBID ë²„ì „: {version_response.text.strip()}")
        else:
            print(f"GROBID ì„œë¹„ìŠ¤ ìƒíƒœ ë¶ˆëŸ‰: {response.status_code}")

    except Exception as e:
        print(f"GROBID ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")

def generate_system_report(pg_stats):
    """ì‹œìŠ¤í…œ ì¢…í•© í‰ê°€ ë³´ê³ ì„œ ìƒì„±"""
    print("\n" + "=" * 60)
    print("5. ì‹œìŠ¤í…œ ì¢…í•© í‰ê°€")
    print("=" * 60)

    if not pg_stats:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë¡œ í‰ê°€ ë¶ˆê°€")
        return

    total_papers = pg_stats['total_papers']

    if total_papers == 0:
        print("âŒ ë…¼ë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“Š ì´ {total_papers:,}ê°œì˜ ë…¼ë¬¸ì´ ì‹œìŠ¤í…œì— ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n")

    # ê° ë‹¨ê³„ë³„ ì™„ë£Œë„ í‰ê°€
    embedding_ratio = (pg_stats['papers_with_embeddings'] / total_papers) * 100
    grobid_ratio = (pg_stats['grobid_processed'] / total_papers) * 100
    keyword_ratio = (pg_stats['papers_with_keywords'] / total_papers) * 100

    print("ğŸ“ˆ ì²˜ë¦¬ ë‹¨ê³„ë³„ ì™„ë£Œë„:")
    print(f"  ğŸ” ì„ë² ë”© ìƒì„±: {embedding_ratio:.1f}% {'âœ…' if embedding_ratio > 80 else 'âš ï¸' if embedding_ratio > 50 else 'âŒ'}")
    print(f"  ğŸ“„ GROBID ì²˜ë¦¬: {grobid_ratio:.1f}% {'âœ…' if grobid_ratio > 80 else 'âš ï¸' if grobid_ratio > 50 else 'âŒ'}")
    print(f"  ğŸ·ï¸  í‚¤ì›Œë“œ ì¶”ì¶œ: {keyword_ratio:.1f}% {'âœ…' if keyword_ratio > 80 else 'âš ï¸' if keyword_ratio > 50 else 'âŒ'}")

    # ì‹œìŠ¤í…œ ìƒíƒœ í‰ê°€
    if embedding_ratio > 80 and grobid_ratio > 80:
        print(f"\nğŸ‰ ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!")
        print("   - ë…¼ë¬¸ ì¶”ì²œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif embedding_ratio > 50 or grobid_ratio > 50:
        print(f"\nâš ï¸  ì‹œìŠ¤í…œì´ ë¶€ë¶„ì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        print("   - ì¼ë¶€ ë…¼ë¬¸ì— ëŒ€í•´ì„œë§Œ ì¶”ì²œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   - ì„ë² ë”© ìƒì„± ë° GROBID ì²˜ë¦¬ë¥¼ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")

    # ìµœê·¼ í™œë™ í‰ê°€
    if pg_stats['recent_papers'] > 0:
        print(f"\nğŸ“… ìµœê·¼ 7ì¼ê°„ {pg_stats['recent_papers']:,}ê°œì˜ ìƒˆë¡œìš´ ë…¼ë¬¸ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    print("RSP ë…¼ë¬¸ ì¶”ì²œ ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ì ê²€ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # 1. PostgreSQL ìƒíƒœ í™•ì¸
    pg_stats = check_postgresql_status()

    # 2. HBase ìƒíƒœ í™•ì¸
    check_hbase_status()

    # 3. OpenSearch ìƒíƒœ í™•ì¸
    check_opensearch_status()

    # 4. GROBID ì„œë¹„ìŠ¤ í™•ì¸
    check_grobid_service()

    # 5. ì¢…í•© í‰ê°€
    generate_system_report(pg_stats)

if __name__ == "__main__":
    main()