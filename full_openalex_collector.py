#!/usr/bin/env python3
"""
OpenAlex APIë¡œ ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘í•˜ê³  ëª¨ë“  ê´€ë ¨ í…Œì´ë¸”ì— ì €ì¥
(papers, authors, concepts, journals, paper_authors, paper_concepts)
"""

import requests
import psycopg2
import psycopg2.extras
import json
import os
from datetime import datetime
import time

# PostgreSQL ì—°ê²° ì„¤ì •
DB_CONFIG = {
    'host': os.getenv('POSTGRES_HOST', 'localhost'),
    'port': int(os.getenv('POSTGRES_PORT', 5432)),
    'database': os.getenv('POSTGRES_DB', 'papers_db'),
    'user': os.getenv('POSTGRES_USER', 'postgres'),
    'password': os.getenv('POSTGRES_PASSWORD', 'postgres123')
}

class FullOpenAlexCollector:
    def __init__(self):
        self.base_url = "https://api.openalex.org/works"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (RSP-Paper-System/1.0; mailto:test@example.com)'
        }

    def fetch_papers(self, query="machine learning", count=10):
        """OpenAlex APIì—ì„œ Computer Science ë¶„ì•¼ ë…¼ë¬¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""

        # ===================================================
        # ğŸ¯ íŒ€ì›ë³„ Concept ë¶„ë‹´ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
        # ===================================================
        # ê° íŒ€ì›ì€ ì•„ë˜ 5ê°œ concept ì¤‘ í•˜ë‚˜ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
        # ë‹´ë‹¹ìëŠ” í•´ë‹¹ ë¼ì¸ì˜ ì£¼ì„(#)ì„ ì œê±°í•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.
        # ===================================================

        # ğŸ‘¤ ìˆ˜ì§„: Machine Learning ë‹´ë‹¹
        # assigned_concept = 'C78519656'  # Machine Learning (ìˆ˜ì§„ì´ ì´ ì¤„ ì£¼ì„ í•´ì œ)

        # ğŸ‘¤ ìŠ¹ì—°: Artificial Intelligence ë‹´ë‹¹
        # assigned_concept = 'C119857082'  # Artificial Intelligence (ìŠ¹ì—°ì´ ì´ ì¤„ ì£¼ì„ í•´ì œ)

        # ğŸ‘¤ ìŠ¹ê· : Computer Vision ë‹´ë‹¹
        # assigned_concept = 'C162324750'  # Computer Vision (ìŠ¹ê· ì´ ì´ ì¤„ ì£¼ì„ í•´ì œ)

        # ğŸ‘¤ ê²½ì°¬: Natural Language Processing ë‹´ë‹¹
        # assigned_concept = 'C2779118'   # Natural Language Processing (ê²½ì°¬ì´ ì´ ì¤„ ì£¼ì„ í•´ì œ)

        # ğŸ‘¤ ë¯¼: Computer Science ì „ë°˜ ë‹´ë‹¹
        # assigned_concept = 'C41008148'  # Computer Science (ë¯¼ì´ ì´ ì¤„ ì£¼ì„ í•´ì œ)

        # ===================================================
        # âš ï¸  ì£¼ì˜: ìœ„ì—ì„œ ì •í™•íˆ í•˜ë‚˜ë§Œ ì£¼ì„ í•´ì œí•˜ì„¸ìš”!
        # ===================================================

        # ê¸°ë³¸ê°’ ì„¤ì • (ì•„ë¬´ê²ƒë„ ì£¼ì„ í•´ì œ ì•ˆ í–ˆì„ ë•Œ)
        try:
            concept_filter = assigned_concept
        except NameError:
            concept_filter = 'C41008148'  # ê¸°ë³¸ê°’: Computer Science
            print("âš ï¸  ê²½ê³ : conceptê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš© ì¤‘...")
            print("   ë‹´ë‹¹ concept ë¼ì¸ì˜ ì£¼ì„(#)ì„ ì œê±°í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")

        # Conceptë³„ ì„¤ëª… ë§¤í•‘
        concept_names = {
            'C78519656': 'Machine Learning (ë¨¸ì‹ ëŸ¬ë‹)',
            'C119857082': 'Artificial Intelligence (ì¸ê³µì§€ëŠ¥)',
            'C162324750': 'Computer Vision (ì»´í“¨í„° ë¹„ì „)',
            'C2779118': 'Natural Language Processing (ìì—°ì–´ ì²˜ë¦¬)',
            'C41008148': 'Computer Science (ì»´í“¨í„° ê³¼í•™ ì „ë°˜)'
        }

        print(f"ğŸ¯ ìˆ˜ì§‘ ëŒ€ìƒ: {concept_names.get(concept_filter, concept_filter)}")
        print(f"ğŸ“Š ìˆ˜ì§‘ ê°œìˆ˜: {count}ê°œ ë…¼ë¬¸")
        print("-" * 60)

        # ===================================================
        # ğŸ¯ íŒ€ì›ë³„ Concept ë¶„ì•¼ í•„í„°ë§ë§Œ ì ìš©
        # (í•´ë‹¹ ë¶„ì•¼ì˜ ëª¨ë“  ë…¼ë¬¸ì„ ìˆ˜ì§‘)
        # ===================================================
        filter_string = f'concepts.id:{concept_filter}'

        params = {
            'search': query,
            'filter': filter_string,
            'per-page': min(count, 25),  # API ì œí•œ
            'sort': 'cited_by_count:desc'
        }

        try:
            print(f"ğŸ” OpenAlex API ìš”ì²­: '{query}', {count}ê°œ ë…¼ë¬¸...")
            response = requests.get(self.base_url, params=params, headers=self.headers)
            response.raise_for_status()

            data = response.json()
            papers = data.get('results', [])

            print(f"âœ… {len(papers)}ê°œ ë…¼ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ")
            return papers

        except Exception as e:
            print(f"âŒ OpenAlex API ìš”ì²­ ì‹¤íŒ¨: {e}")
            return []

    def save_journal(self, host_venue, cursor):
        """ì €ë„ ì •ë³´ ì €ì¥í•˜ê³  journal_id ë°˜í™˜"""
        if not host_venue or not host_venue.get('id'):
            return None

        try:
            openalex_source_id = host_venue.get('id', '').replace('https://openalex.org/', '')
            name = host_venue.get('display_name', '').strip()

            if not name:
                return None

            # ì €ë„ ì •ë³´ ì¶”ì¶œ
            issn_data = host_venue.get('issn', [])
            issn_l = host_venue.get('issn_l')
            is_oa = host_venue.get('is_oa', False)
            source_type = host_venue.get('type', 'journal')

            insert_journal_sql = """
            INSERT INTO journals (
                openalex_source_id, name, issn_l, issn, is_oa, source_type, created_at
            ) VALUES (
                %(openalex_source_id)s, %(name)s, %(issn_l)s, %(issn)s, %(is_oa)s, %(source_type)s, NOW()
            ) ON CONFLICT (openalex_source_id) DO UPDATE SET
                name = EXCLUDED.name,
                issn_l = EXCLUDED.issn_l,
                issn = EXCLUDED.issn,
                is_oa = EXCLUDED.is_oa,
                updated_at = NOW()
            RETURNING id
            """

            cursor.execute(insert_journal_sql, {
                'openalex_source_id': openalex_source_id,
                'name': name,
                'issn_l': issn_l,
                'issn': json.dumps(issn_data) if issn_data else None,
                'is_oa': is_oa,
                'source_type': source_type
            })

            journal_id = cursor.fetchone()['id']
            print(f"  ğŸ““ ì €ë„ ì €ì¥: {name}")
            return journal_id

        except Exception as e:
            print(f"âŒ ì €ë„ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def save_author(self, author_data, cursor):
        """ì €ì ì •ë³´ ì €ì¥í•˜ê³  author_id ë°˜í™˜ (ì´ë¦„ ê¸°ì¤€ ì¤‘ë³µ ë°©ì§€)"""
        if not author_data or not author_data.get('display_name'):
            return None

        try:
            openalex_author_id = author_data.get('id', '').replace('https://openalex.org/', '')
            name = author_data.get('display_name', '').strip()
            orcid = author_data.get('orcid', '').replace('https://orcid.org/', '') if author_data.get('orcid') else None

            # 1. ë¨¼ì € ê°™ì€ ì´ë¦„ì˜ ì €ìê°€ ìˆëŠ”ì§€ í™•ì¸
            cursor.execute("SELECT id FROM authors WHERE name = %s LIMIT 1", (name,))
            existing_author = cursor.fetchone()

            if existing_author:
                # ì´ë¯¸ ê°™ì€ ì´ë¦„ì˜ ì €ìê°€ ìˆìœ¼ë©´ ê¸°ì¡´ ID ë°˜í™˜
                return existing_author['id']

            # 2. ìƒˆë¡œìš´ ì €ì ì €ì¥ (OpenAlex ID ê¸°ì¤€ ì¤‘ë³µ ë°©ì§€)
            insert_author_sql = """
            INSERT INTO authors (
                openalex_author_id, name, orcid, created_at
            ) VALUES (
                %(openalex_author_id)s, %(name)s, %(orcid)s, NOW()
            ) ON CONFLICT (openalex_author_id) DO UPDATE SET
                name = EXCLUDED.name,
                orcid = EXCLUDED.orcid,
                updated_at = NOW()
            RETURNING id
            """

            cursor.execute(insert_author_sql, {
                'openalex_author_id': openalex_author_id,
                'name': name,
                'orcid': orcid
            })

            author_id = cursor.fetchone()['id']
            return author_id

        except Exception as e:
            print(f"âŒ ì €ì ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def save_concept(self, concept_data, cursor):
        """ê°œë… ì •ë³´ ì €ì¥í•˜ê³  concept_id ë°˜í™˜"""
        if not concept_data or not concept_data.get('display_name'):
            return None

        try:
            openalex_concept_id = concept_data.get('id', '').replace('https://openalex.org/', '')
            name = concept_data.get('display_name', '').strip()
            level = concept_data.get('level', 0)
            works_count = concept_data.get('works_count', 0)

            insert_concept_sql = """
            INSERT INTO concepts (
                openalex_concept_id, name, level, works_count, created_at
            ) VALUES (
                %(openalex_concept_id)s, %(name)s, %(level)s, %(works_count)s, NOW()
            ) ON CONFLICT (openalex_concept_id) DO UPDATE SET
                name = EXCLUDED.name,
                level = EXCLUDED.level,
                works_count = EXCLUDED.works_count,
                updated_at = NOW()
            RETURNING id
            """

            cursor.execute(insert_concept_sql, {
                'openalex_concept_id': openalex_concept_id,
                'name': name,
                'level': level,
                'works_count': works_count
            })

            concept_id = cursor.fetchone()['id']
            return concept_id

        except Exception as e:
            print(f"âŒ ê°œë… ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def find_journal_by_issn_or_name(self, location_data, journal_name, cursor):
        """ISSN ìš°ì„ , ì €ë„ëª… ì°¨ìˆœìœ¼ë¡œ ì €ë„ ë§¤ì¹­"""
        try:
            # 1ìˆœìœ„: ISSN-Lë¡œ ë§¤ì¹­
            if location_data and location_data.get('source'):
                source = location_data['source']
                issn_l = source.get('issn_l')
                if issn_l:
                    cursor.execute(
                        "SELECT id FROM journals WHERE issn_l = %s LIMIT 1",
                        (issn_l,)
                    )
                    result = cursor.fetchone()
                    if result:
                        print(f"    âœ… ISSN-L ë§¤ì¹­: {issn_l}")
                        return result['id']

                # 2ìˆœìœ„: ISSN ë°°ì—´ì—ì„œ í•˜ë‚˜ë¼ë„ ë§¤ì¹­
                issn_list = source.get('issn')
                if issn_list:
                    for issn in issn_list:
                        cursor.execute(
                            "SELECT id FROM journals WHERE issn ? %s LIMIT 1",
                            (issn,)
                        )
                        result = cursor.fetchone()
                        if result:
                            print(f"    âœ… ISSN ë§¤ì¹­: {issn}")
                            return result['id']

                # 3ìˆœìœ„: OpenAlex Source ID ë§¤ì¹­
                openalex_source_id = source.get('id', '').replace('https://openalex.org/', '')
                if openalex_source_id:
                    cursor.execute(
                        "SELECT id FROM journals WHERE openalex_source_id = %s LIMIT 1",
                        (openalex_source_id,)
                    )
                    result = cursor.fetchone()
                    if result:
                        print(f"    âœ… OpenAlex ID ë§¤ì¹­: {openalex_source_id}")
                        return result['id']

            # 4ìˆœìœ„: ì €ë„ëª… ì •í™• ë§¤ì¹­
            if journal_name:
                cursor.execute(
                    "SELECT id FROM journals WHERE name ILIKE %s LIMIT 1",
                    (journal_name,)
                )
                result = cursor.fetchone()
                if result:
                    print(f"    âœ… ì €ë„ëª… ì •í™• ë§¤ì¹­: {journal_name}")
                    return result['id']

                # 5ìˆœìœ„: ì €ë„ëª… ë¶€ë¶„ ë§¤ì¹­
                cursor.execute(
                    "SELECT id FROM journals WHERE name ILIKE %s LIMIT 1",
                    (f"%{journal_name}%",)
                )
                result = cursor.fetchone()
                if result:
                    print(f"    âš ï¸ ì €ë„ëª… ë¶€ë¶„ ë§¤ì¹­: {journal_name}")
                    return result['id']

            return None

        except Exception as e:
            print(f"âŒ ì €ë„ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            return None

    def save_paper_complete(self, paper):
        """ë…¼ë¬¸ê³¼ ëª¨ë“  ê´€ë ¨ ë°ì´í„°ë¥¼ ì™„ì „íˆ ì €ì¥"""
        try:
            with psycopg2.connect(**DB_CONFIG) as conn:
                with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:

                    # 1. ì €ë„ ì •ë³´ ì €ì¥
                    journal_id = None
                    host_venue = paper.get('host_venue')
                    if host_venue:
                        journal_id = self.save_journal(host_venue, cursor)

                    # 2. ë…¼ë¬¸ ê¸°ë³¸ ì •ë³´ ì €ì¥
                    openalex_id = paper.get('id', '').replace('https://openalex.org/', '')
                    title = (paper.get('title') or '').strip()
                    abstract = paper.get('abstract_inverted_index')

                    # Abstract ë³µì› (OpenAlexëŠ” inverted indexë¡œ ì œê³µ)
                    abstract_text = self.reconstruct_abstract(abstract) if abstract else ""

                    doi = paper.get('doi', '').replace('https://doi.org/', '') if paper.get('doi') else None

                    # PDF URL ì¶”ì¶œ
                    pdf_url = None
                    open_access = paper.get('open_access', {})
                    if open_access.get('oa_url'):
                        pdf_url = open_access['oa_url']

                    citation_count = paper.get('cited_by_count', 0)
                    publication_date = paper.get('publication_date')
                    is_open_access = open_access.get('is_oa', False)

                    # ì €ë„ ì •ë³´ - primary_locationì—ì„œ ì¶”ì¶œ
                    journal_id = None
                    journal_name = None
                    publisher = None

                    # 1. primary_locationì—ì„œ ì €ë„ ì°¾ê¸°
                    primary_location = paper.get('primary_location')
                    if primary_location and primary_location.get('source'):
                        source = primary_location['source']
                        if source.get('type') == 'journal':
                            journal_name = source.get('display_name')
                            publisher = source.get('host_organization_name')

                    # 2. primary_locationì— ì—†ìœ¼ë©´ locationsì—ì„œ ì €ë„ íƒ€ì… ì°¾ê¸°
                    if not journal_name:
                        locations = paper.get('locations', [])
                        for location in locations:
                            source = location.get('source')
                            if source and source.get('type') == 'journal':
                                journal_name = source.get('display_name')
                                publisher = source.get('host_organization_name')
                                break

                    # 3. ê¸°ì¡´ ì €ë„ í…Œì´ë¸”ì—ì„œ ë§¤ì¹­ë˜ëŠ” ì €ë„ ì°¾ê¸°
                    if journal_name:
                        journal_id = self.find_journal_by_issn_or_name(primary_location, journal_name, cursor)
                        if journal_id:
                            print(f"  ğŸ““ ì €ë„ ë§¤ì¹­ ì„±ê³µ: {journal_name} -> ID {journal_id}")
                        else:
                            print(f"  âš ï¸ ì €ë„ ë§¤ì¹­ ì‹¤íŒ¨: {journal_name}")
                    else:
                        print(f"  âŒ ì €ë„ ì •ë³´ ì—†ìŒ (locationsì—ì„œë„ ì €ë„ íƒ€ì… ë°œê²¬ ëª»í•¨)")

                    # ë…¼ë¬¸ íƒ€ì…ê³¼ í‚¤ì›Œë“œ ì •ë³´ ì¶”ì¶œ
                    paper_type = paper.get('type', 'article')

                    # í‚¤ì›Œë“œ ì •ë³´ ì¶”ì¶œ (keywords, concepts, topics í™œìš©)
                    keywords_list = []

                    # 1. keywords í•„ë“œ (ë³´í†µ ë¹„ì–´ìˆì§€ë§Œ ìˆìœ¼ë©´ í™œìš©)
                    if paper.get('keywords'):
                        for kw in paper['keywords']:
                            if isinstance(kw, dict) and kw.get('display_name'):
                                keywords_list.append(kw['display_name'])
                            elif isinstance(kw, str):
                                keywords_list.append(kw)

                    # 2. conceptsì—ì„œ ë†’ì€ ì ìˆ˜ í•­ëª©ë“¤ ì¶”ì¶œ (score > 0.5)
                    if paper.get('concepts'):
                        for concept in paper['concepts'][:10]:  # ìµœëŒ€ 10ê°œ
                            if isinstance(concept, dict) and concept.get('score', 0) > 0.5:
                                name = concept.get('display_name', '')
                                if name and name not in keywords_list:  # ì¤‘ë³µ ë°©ì§€
                                    keywords_list.append(name)

                    # 3. topicsì—ì„œ ì¶”ì¶œ (ìµœëŒ€ 3ê°œ)
                    if paper.get('topics'):
                        for topic in paper['topics'][:3]:
                            if isinstance(topic, dict) and topic.get('display_name'):
                                name = topic['display_name']
                                if name and name not in keywords_list:  # ì¤‘ë³µ ë°©ì§€
                                    keywords_list.append(name)

                    # ì¤‘ë³µ ì œê±°í•˜ê³  ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ (PostgreSQL array íƒ€ì…ìœ¼ë¡œ ì €ì¥)
                    # ë¹ˆ ë¬¸ìì—´ ì œê±° ë° ìµœëŒ€ 20ê°œ ì œí•œ
                    keywords_list = [kw.strip() for kw in keywords_list if kw and kw.strip()]
                    keywords_list = list(dict.fromkeys(keywords_list))[:20]  # ìˆœì„œ ìœ ì§€í•˜ë©° ì¤‘ë³µ ì œê±°
                    keywords = keywords_list if keywords_list else None

                    insert_paper_sql = """
                    INSERT INTO papers (
                        openalex_paper_id, title, abstract_text, doi, pdf_url,
                        citation_count, publication_date, is_open_access,
                        publisher, journal_id, type, keywords, created_at
                    ) VALUES (
                        %(openalex_paper_id)s, %(title)s, %(abstract_text)s, %(doi)s, %(pdf_url)s,
                        %(citation_count)s, %(publication_date)s, %(is_open_access)s,
                        %(publisher)s, %(journal_id)s, %(type)s, %(keywords)s, NOW()
                    ) ON CONFLICT (openalex_paper_id) DO UPDATE SET
                        citation_count = EXCLUDED.citation_count,
                        keywords = EXCLUDED.keywords,
                        updated_at = NOW()
                    RETURNING id
                    """

                    cursor.execute(insert_paper_sql, {
                        'openalex_paper_id': openalex_id,
                        'title': title,
                        'abstract_text': abstract_text,
                        'doi': doi,
                        'pdf_url': pdf_url,
                        'citation_count': citation_count,
                        'publication_date': publication_date,
                        'is_open_access': is_open_access,
                        'publisher': publisher,
                        'journal_id': journal_id,
                        'type': paper_type,
                        'keywords': json.dumps(keywords) if keywords else None
                    })

                    paper_id = cursor.fetchone()['id']
                    print(f"âœ… ë…¼ë¬¸ ì €ì¥: ID {paper_id}, '{title[:30]}...'")

                    # 3. ì €ì ì •ë³´ ì €ì¥ ë° ê´€ê³„ ì„¤ì •
                    authorships = paper.get('authorships', [])
                    for idx, authorship in enumerate(authorships):
                        author_info = authorship.get('author', {})
                        if author_info:
                            author_id = self.save_author(author_info, cursor)
                            if author_id:
                                # ì†Œì†ê¸°ê´€ ì •ë³´
                                institutions = authorship.get('institutions', [])
                                affiliation = institutions[0].get('display_name') if institutions else None

                                if affiliation:
                                    # ì €ì ì†Œì† ì—…ë°ì´íŠ¸
                                    cursor.execute(
                                        "UPDATE authors SET affiliation = %s WHERE id = %s",
                                        (affiliation, author_id)
                                    )

                                # ë…¼ë¬¸-ì €ì ê´€ê³„ ì €ì¥
                                is_corresponding = authorship.get('is_corresponding', False)

                                cursor.execute("""
                                INSERT INTO paper_authors (paper_id, author_id, author_order, is_corresponding)
                                VALUES (%s, %s, %s, %s)
                                ON CONFLICT (paper_id, author_id) DO UPDATE SET
                                    author_order = EXCLUDED.author_order,
                                    is_corresponding = EXCLUDED.is_corresponding
                                """, (paper_id, author_id, idx + 1, is_corresponding))

                    # 4. ê°œë… ì •ë³´ ì €ì¥ ë° ê´€ê³„ ì„¤ì •
                    concepts = paper.get('concepts', [])
                    for concept in concepts:
                        concept_id = self.save_concept(concept, cursor)
                        if concept_id:
                            relevance_score = concept.get('score', 0.0)

                            cursor.execute("""
                            INSERT INTO paper_concepts (paper_id, concept_id, relevance_score)
                            VALUES (%s, %s, %s)
                            ON CONFLICT (paper_id, concept_id) DO UPDATE SET
                                relevance_score = EXCLUDED.relevance_score
                            """, (paper_id, concept_id, relevance_score))

                    print(f"  ğŸ‘¥ ì €ì {len(authorships)}ëª…, ğŸ·ï¸ ê°œë… {len(concepts)}ê°œ ì €ì¥ ì™„ë£Œ")
                    return paper_id

        except Exception as e:
            print(f"âŒ ë…¼ë¬¸ ì €ì¥ ì‹¤íŒ¨ '{paper.get('title', 'Unknown')[:30]}...': {e}")
            return None

    def reconstruct_abstract(self, inverted_index):
        """OpenAlexì˜ inverted indexì—ì„œ abstract ë³µì›"""
        if not inverted_index:
            return ""

        try:
            # ë‹¨ì–´ ìœ„ì¹˜ ë§¤í•‘
            word_positions = {}
            for word, positions in inverted_index.items():
                for pos in positions:
                    word_positions[pos] = word

            # ìœ„ì¹˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•´ì„œ í…ìŠ¤íŠ¸ ë³µì›
            sorted_positions = sorted(word_positions.keys())
            abstract_words = [word_positions[pos] for pos in sorted_positions]

            return ' '.join(abstract_words)
        except:
            return ""

    def collect_and_save(self, query="machine learning", count=10):
        """ì „ì²´ ìˆ˜ì§‘ ë° ì €ì¥ í”„ë¡œì„¸ìŠ¤"""
        print(f"ğŸš€ OpenAlex ì „ì²´ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"   ì¿¼ë¦¬: '{query}', ê°œìˆ˜: {count}")

        # 1. OpenAlex APIì—ì„œ ë…¼ë¬¸ ë°ì´í„° ìˆ˜ì§‘
        papers = self.fetch_papers(query=query, count=count)

        if not papers:
            print("âŒ ìˆ˜ì§‘ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
            return

        # 2. ê° ë…¼ë¬¸ì„ ëª¨ë“  ê´€ë ¨ í…Œì´ë¸”ì— ì €ì¥
        saved_count = 0
        for i, paper in enumerate(papers, 1):
            print(f"\nğŸ“„ ë…¼ë¬¸ {i}/{len(papers)} ì²˜ë¦¬ ì¤‘...")

            paper_id = self.save_paper_complete(paper)
            if paper_id:
                saved_count += 1

            # API ì†ë„ ì œí•œ ì¤€ìˆ˜
            time.sleep(0.1)

        print(f"\nğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ: {saved_count}/{len(papers)}ê°œ ë…¼ë¬¸ ì €ì¥ë¨")

        # 3. ìµœì¢… í†µê³„ ì¶œë ¥
        self.print_db_statistics()

    def print_db_statistics(self):
        """DB í†µê³„ ì¶œë ¥"""
        try:
            with psycopg2.connect(**DB_CONFIG) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("SELECT COUNT(*) FROM papers")
                    papers_count = cursor.fetchone()[0]

                    cursor.execute("SELECT COUNT(*) FROM papers WHERE pdf_url IS NOT NULL")
                    papers_with_pdf = cursor.fetchone()[0]

                    cursor.execute("SELECT COUNT(*) FROM authors")
                    authors_count = cursor.fetchone()[0]

                    cursor.execute("SELECT COUNT(*) FROM concepts")
                    concepts_count = cursor.fetchone()[0]

                    cursor.execute("SELECT COUNT(*) FROM journals")
                    journals_count = cursor.fetchone()[0]

                    print(f"\nğŸ“Š DB í˜„í™©:")
                    print(f"   ì´ ë…¼ë¬¸: {papers_count}ê°œ")
                    print(f"   PDF ìˆëŠ” ë…¼ë¬¸: {papers_with_pdf}ê°œ")
                    print(f"   ì €ì: {authors_count}ëª…")
                    print(f"   ê°œë…: {concepts_count}ê°œ")
                    print(f"   ì €ë„: {journals_count}ê°œ")

        except Exception as e:
            print(f"âŒ DB í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

def main():
    import argparse

    parser = argparse.ArgumentParser(description='OpenAlex ë…¼ë¬¸ ìˆ˜ì§‘ê¸°')
    parser.add_argument('--query', default='machine learning neural networks', help='ê²€ìƒ‰ ì¿¼ë¦¬')
    parser.add_argument('--count', type=int, default=15, help='ìˆ˜ì§‘í•  ë…¼ë¬¸ ìˆ˜')

    args = parser.parse_args()

    collector = FullOpenAlexCollector()
    collector.collect_and_save(query=args.query, count=args.count)

if __name__ == "__main__":
    main()