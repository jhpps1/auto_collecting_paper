#!/usr/bin/env python3
"""
íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¡œê±°

ê° ì‘ì—…ì˜ ì²˜ë¦¬ ì‹œê°„, ì„±ê³µ/ì‹¤íŒ¨ìœ¨, ì²˜ë¦¬ëŸ‰ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê¸°ë¡
"""

import time
import json
import psycopg2
from datetime import datetime
from contextlib import contextmanager
from typing import Dict, Any, Optional
import threading
import os

# PostgreSQL ì—°ê²° ì„¤ì •
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'papers_db',
    'user': 'postgres',
    'password': 'postgres123'
}

class PerformanceLogger:
    def __init__(self):
        self.setup_metrics_table()
        self.lock = threading.Lock()

    def setup_metrics_table(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…Œì´ë¸” ìƒì„±"""
        try:
            with psycopg2.connect(**DB_CONFIG) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS performance_metrics (
                            id SERIAL PRIMARY KEY,
                            timestamp TIMESTAMP DEFAULT NOW(),
                            stage VARCHAR(50) NOT NULL,
                            operation VARCHAR(100) NOT NULL,
                            duration_seconds FLOAT NOT NULL,
                            success BOOLEAN NOT NULL,
                            paper_id INTEGER,
                            error_message TEXT,
                            metadata JSONB,
                            created_at TIMESTAMP DEFAULT NOW()
                        )
                    """)

                    # ì¸ë±ìŠ¤ ìƒì„±
                    cursor.execute("""
                        CREATE INDEX IF NOT EXISTS idx_performance_timestamp
                        ON performance_metrics(timestamp)
                    """)
                    cursor.execute("""
                        CREATE INDEX IF NOT EXISTS idx_performance_stage
                        ON performance_metrics(stage)
                    """)

                    conn.commit()
                    print("âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…Œì´ë¸” ì„¤ì • ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ ë©”íŠ¸ë¦­ í…Œì´ë¸” ì„¤ì • ì‹¤íŒ¨: {e}")

    def log_performance(self, stage: str, operation: str, duration: float,
                       success: bool, paper_id: Optional[int] = None,
                       error_message: Optional[str] = None,
                       metadata: Optional[Dict] = None):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…"""
        try:
            with self.lock:
                with psycopg2.connect(**DB_CONFIG) as conn:
                    with conn.cursor() as cursor:
                        cursor.execute("""
                            INSERT INTO performance_metrics
                            (stage, operation, duration_seconds, success, paper_id, error_message, metadata)
                            VALUES (%s, %s, %s, %s, %s, %s, %s)
                        """, (stage, operation, duration, success, paper_id, error_message,
                              json.dumps(metadata) if metadata else None))
                        conn.commit()

        except Exception as e:
            print(f"âŒ ì„±ëŠ¥ ë¡œê¹… ì‹¤íŒ¨: {e}")

    @contextmanager
    def measure_operation(self, stage: str, operation: str,
                         paper_id: Optional[int] = None,
                         metadata: Optional[Dict] = None):
        """ì‘ì—… ì‹œê°„ ì¸¡ì • ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        start_time = time.time()
        success = False
        error_message = None

        try:
            yield
            success = True
        except Exception as e:
            error_message = str(e)
            raise
        finally:
            duration = time.time() - start_time
            self.log_performance(stage, operation, duration, success,
                               paper_id, error_message, metadata)

    def get_recent_metrics(self, hours: int = 24) -> Dict[str, Any]:
        """ìµœê·¼ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        try:
            with psycopg2.connect(**DB_CONFIG) as conn:
                with conn.cursor() as cursor:
                    # ìŠ¤í…Œì´ì§€ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„
                    cursor.execute("""
                        SELECT
                            stage,
                            operation,
                            COUNT(*) as total_operations,
                            AVG(duration_seconds) as avg_duration,
                            SUM(CASE WHEN success THEN 1 ELSE 0 END) as success_count,
                            COUNT(*) - SUM(CASE WHEN success THEN 1 ELSE 0 END) as failure_count,
                            MAX(duration_seconds) as max_duration,
                            MIN(duration_seconds) as min_duration
                        FROM performance_metrics
                        WHERE timestamp >= NOW() - INTERVAL '%s hours'
                        GROUP BY stage, operation
                        ORDER BY stage, operation
                    """, (hours,))

                    metrics = cursor.fetchall()

                    result = {
                        'summary': {},
                        'detailed': []
                    }

                    stage_totals = {}

                    for metric in metrics:
                        stage, operation, total, avg_duration, success, failure, max_dur, min_dur = metric

                        success_rate = (success / total * 100) if total > 0 else 0
                        throughput = 3600 / avg_duration if avg_duration > 0 else 0

                        detailed_metric = {
                            'stage': stage,
                            'operation': operation,
                            'total_operations': total,
                            'avg_duration': round(avg_duration, 3),
                            'success_rate': round(success_rate, 1),
                            'throughput_per_hour': round(throughput, 0),
                            'success_count': success,
                            'failure_count': failure,
                            'max_duration': round(max_dur, 3),
                            'min_duration': round(min_dur, 3)
                        }

                        result['detailed'].append(detailed_metric)

                        # ìŠ¤í…Œì´ì§€ë³„ ì§‘ê³„
                        if stage not in stage_totals:
                            stage_totals[stage] = {
                                'total_operations': 0,
                                'total_duration': 0,
                                'success_count': 0,
                                'failure_count': 0
                            }

                        stage_totals[stage]['total_operations'] += total
                        stage_totals[stage]['total_duration'] += avg_duration * total
                        stage_totals[stage]['success_count'] += success
                        stage_totals[stage]['failure_count'] += failure

                    # ìŠ¤í…Œì´ì§€ë³„ ìš”ì•½ ê³„ì‚°
                    for stage, totals in stage_totals.items():
                        if totals['total_operations'] > 0:
                            avg_duration = totals['total_duration'] / totals['total_operations']
                            success_rate = totals['success_count'] / totals['total_operations'] * 100
                            throughput = 3600 / avg_duration if avg_duration > 0 else 0

                            result['summary'][stage] = {
                                'avg_duration': round(avg_duration, 3),
                                'success_rate': round(success_rate, 1),
                                'throughput_per_hour': round(throughput, 0),
                                'total_operations': totals['total_operations']
                            }

                    return result

        except Exception as e:
            print(f"âŒ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def get_pipeline_bottlenecks(self, hours: int = 24) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ë³‘ëª© ë¶„ì„"""
        try:
            metrics = self.get_recent_metrics(hours)
            summary = metrics.get('summary', {})

            bottlenecks = []
            stages = ['openalex', 'pdf_grobid', 'embedding', 'similarity']

            max_duration = 0
            slowest_stage = None

            for stage in stages:
                if stage in summary:
                    duration = summary[stage]['avg_duration']
                    if duration > max_duration:
                        max_duration = duration
                        slowest_stage = stage

                    bottlenecks.append({
                        'stage': stage,
                        'avg_duration': duration,
                        'throughput': summary[stage]['throughput_per_hour'],
                        'success_rate': summary[stage]['success_rate'],
                        'is_bottleneck': False
                    })

            # ë³‘ëª© í‘œì‹œ
            for bottleneck in bottlenecks:
                if bottleneck['stage'] == slowest_stage:
                    bottleneck['is_bottleneck'] = True

            return {
                'bottlenecks': bottlenecks,
                'slowest_stage': slowest_stage,
                'max_duration': max_duration,
                'analysis_period_hours': hours
            }

        except Exception as e:
            print(f"âŒ ë³‘ëª© ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

# ì „ì—­ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
_performance_logger = None

def get_performance_logger():
    """ì„±ëŠ¥ ë¡œê±° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _performance_logger
    if _performance_logger is None:
        _performance_logger = PerformanceLogger()
    return _performance_logger

# í¸ì˜ í•¨ìˆ˜ë“¤
def log_openalex_operation(operation: str, duration: float, success: bool,
                          paper_id: Optional[int] = None, metadata: Optional[Dict] = None):
    """OpenAlex ì‘ì—… ë¡œê¹…"""
    logger = get_performance_logger()
    logger.log_performance('openalex', operation, duration, success, paper_id, None, metadata)

def log_pdf_grobid_operation(operation: str, duration: float, success: bool,
                            paper_id: Optional[int] = None, metadata: Optional[Dict] = None):
    """PDF/GROBID ì‘ì—… ë¡œê¹…"""
    logger = get_performance_logger()
    logger.log_performance('pdf_grobid', operation, duration, success, paper_id, None, metadata)

def log_embedding_operation(operation: str, duration: float, success: bool,
                           paper_id: Optional[int] = None, metadata: Optional[Dict] = None):
    """ì„ë² ë”© ì‘ì—… ë¡œê¹…"""
    logger = get_performance_logger()
    logger.log_performance('embedding', operation, duration, success, paper_id, None, metadata)

def log_similarity_operation(operation: str, duration: float, success: bool,
                            paper_id: Optional[int] = None, metadata: Optional[Dict] = None):
    """ìœ ì‚¬ë„ ì‘ì—… ë¡œê¹…"""
    logger = get_performance_logger()
    logger.log_performance('similarity', operation, duration, success, paper_id, None, metadata)

@contextmanager
def measure_openalex(operation: str, paper_id: Optional[int] = None, metadata: Optional[Dict] = None):
    """OpenAlex ì‘ì—… ì¸¡ì •"""
    logger = get_performance_logger()
    with logger.measure_operation('openalex', operation, paper_id, metadata):
        yield

@contextmanager
def measure_pdf_grobid(operation: str, paper_id: Optional[int] = None, metadata: Optional[Dict] = None):
    """PDF/GROBID ì‘ì—… ì¸¡ì •"""
    logger = get_performance_logger()
    with logger.measure_operation('pdf_grobid', operation, paper_id, metadata):
        yield

@contextmanager
def measure_embedding(operation: str, paper_id: Optional[int] = None, metadata: Optional[Dict] = None):
    """ì„ë² ë”© ì‘ì—… ì¸¡ì •"""
    logger = get_performance_logger()
    with logger.measure_operation('embedding', operation, paper_id, metadata):
        yield

@contextmanager
def measure_similarity(operation: str, paper_id: Optional[int] = None, metadata: Optional[Dict] = None):
    """ìœ ì‚¬ë„ ì‘ì—… ì¸¡ì •"""
    logger = get_performance_logger()
    with logger.measure_operation('similarity', operation, paper_id, metadata):
        yield

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    logger = PerformanceLogger()

    # ìƒ˜í”Œ ë°ì´í„° ë¡œê¹…
    logger.log_performance('openalex', 'metadata_collection', 1.5, True, 1001, None, {'query': 'test'})
    logger.log_performance('embedding', 'generate_embedding', 2.3, True, 1001, None, {'model': 'all-mpnet-base-v2'})

    # ë©”íŠ¸ë¦­ ì¡°íšŒ
    metrics = logger.get_recent_metrics(24)
    print("ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
    print(json.dumps(metrics, indent=2, ensure_ascii=False))

    # ë³‘ëª© ë¶„ì„
    bottlenecks = logger.get_pipeline_bottlenecks(24)
    print("\nğŸš¨ ë³‘ëª© ë¶„ì„:")
    print(json.dumps(bottlenecks, indent=2, ensure_ascii=False))