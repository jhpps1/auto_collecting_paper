#!/usr/bin/env python3
"""
PostgreSQLì—ì„œ OpenSearchë¡œ ë…¼ë¬¸ ë°ì´í„° ì¬ìƒ‰ì¸ ìŠ¤í¬ë¦½íŠ¸

PostgreSQLì˜ ëª¨ë“  ë…¼ë¬¸ ë°ì´í„°(ì„ë² ë”© í¬í•¨)ë¥¼ OpenSearchì— ìƒ‰ì¸í•©ë‹ˆë‹¤.
OpenSearch document ID = PostgreSQL papers.id ë¡œ ì„¤ì •í•˜ì—¬ ID ë§¤ì¹­ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
"""

import psycopg2
import psycopg2.extras
import requests
import json
from typing import List, Dict, Any
import time
from datetime import datetime

# ì„¤ì •
POSTGRES_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'papers_db',
    'user': 'postgres',
    'password': 'postgres123'
}

OPENSEARCH_URL = "http://localhost:9200"
INDEX_NAME = "papers"

class PaperReindexer:
    def __init__(self):
        self.postgres_conn = None
        self.total_papers = 0
        self.indexed_papers = 0
        self.failed_papers = 0

    def connect_postgres(self):
        """PostgreSQL ì—°ê²°"""
        try:
            self.postgres_conn = psycopg2.connect(**POSTGRES_CONFIG)
            print("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
            return True
        except Exception as e:
            print(f"âŒ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def fetch_papers_batch(self, offset: int, batch_size: int = 50) -> List[Dict[str, Any]]:
        """PostgreSQLì—ì„œ ë…¼ë¬¸ ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        cursor = self.postgres_conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)

        sql = """
        SELECT
            p.id,
            p.openalex_paper_id,
            p.title,
            p.abstract_text,
            p.doi,
            p.citation_count,
            p.pdf_url,
            p.is_open_access,
            p.publication_date,
            p.keywords,
            p.publisher,
            p.type,
            p.reliability_score,
            p.total_score,
            p.embedding,

            -- ì €ë„ ì •ë³´
            j.name as journal_name,
            j.impact_factor,
            j.h_index as journal_h_index,
            j.jif_quartile,
            j.issn_l,
            j.is_oa as journal_is_oa,

            -- ì €ì ì •ë³´ (ì„œë¸Œì¿¼ë¦¬ë¡œ ì¤‘ë³µ ì œê±°)
            COALESCE(authors_data.authors, '[]'::json) as authors,

            -- ê°œë… ì •ë³´ (ì„œë¸Œì¿¼ë¦¬ë¡œ ì¤‘ë³µ ì œê±°)
            COALESCE(concepts_data.concepts, '[]'::json) as concepts

        FROM papers p
        LEFT JOIN journals j ON p.journal_id = j.id

        -- ì €ì ì •ë³´ ì„œë¸Œì¿¼ë¦¬
        LEFT JOIN (
            SELECT
                pa.paper_id,
                json_agg(
                    json_build_object(
                        'name', a.name,
                        'orcid', a.orcid,
                        'affiliation', a.affiliation,
                        'h_index', a.h_index,
                        'citation_count', a.citation_count
                    ) ORDER BY pa.author_order
                ) as authors
            FROM paper_authors pa
            LEFT JOIN authors a ON pa.author_id = a.id
            WHERE a.id IS NOT NULL
            GROUP BY pa.paper_id
        ) authors_data ON p.id = authors_data.paper_id

        -- ê°œë… ì •ë³´ ì„œë¸Œì¿¼ë¦¬
        LEFT JOIN (
            SELECT
                pc.paper_id,
                json_agg(
                    json_build_object(
                        'name', c.name,
                        'relevance_score', pc.relevance_score,
                        'level', c.level
                    ) ORDER BY pc.relevance_score DESC
                ) as concepts
            FROM paper_concepts pc
            LEFT JOIN concepts c ON pc.concept_id = c.id
            WHERE c.id IS NOT NULL
            GROUP BY pc.paper_id
        ) concepts_data ON p.id = concepts_data.paper_id

        WHERE p.embedding IS NOT NULL  -- ì„ë² ë”©ì´ ìˆëŠ” ë…¼ë¬¸ë§Œ
        ORDER BY p.id
        LIMIT %s OFFSET %s
        """

        cursor.execute(sql, (batch_size, offset))
        return cursor.fetchall()

    def convert_paper_to_opensearch_doc(self, paper: Dict[str, Any]) -> Dict[str, Any]:
        """PostgreSQL ë…¼ë¬¸ ë°ì´í„°ë¥¼ OpenSearch ë¬¸ì„œë¡œ ë³€í™˜"""

        # ì„ë² ë”© ë³€í™˜ (pgvector array -> Python list)
        embedding_list = None
        if paper['embedding']:
            # pgvectorëŠ” ë¬¸ìì—´ë¡œ ì €ì¥ë˜ë¯€ë¡œ íŒŒì‹± í•„ìš”
            embedding_str = str(paper['embedding'])
            if embedding_str.startswith('[') and embedding_str.endswith(']'):
                embedding_list = [float(x) for x in embedding_str[1:-1].split(',')]

        # OpenSearch ë¬¸ì„œ êµ¬ì¡°
        doc = {
            "title": paper['title'],
            "abstract_text": paper['abstract_text'],
            "doi": paper['doi'],
            "citation_count": paper['citation_count'] or 0,
            "pdf_url": paper['pdf_url'],
            "is_open_access": paper['is_open_access'],
            "publication_date": paper['publication_date'].isoformat() if paper['publication_date'] else None,
            "keywords": paper['keywords'] or [],
            "publisher": paper['publisher'],
            "type": paper['type'],
            "reliability_score": float(paper['reliability_score']) if paper['reliability_score'] else None,
            "total_score": float(paper['total_score']) if paper['total_score'] else None,

            "metadata": {
                "openalex_paper_id": paper['openalex_paper_id']
            },

            "journal_info": {
                "name": paper['journal_name'],
                "impact_factor": float(paper['impact_factor']) if paper['impact_factor'] else None,
                "h_index": paper['journal_h_index'],
                "jif_quartile": paper['jif_quartile'],
                "issn_l": paper['issn_l'],
                "is_oa": paper['journal_is_oa']
            },

            "author_details": paper['authors'] if paper['authors'] else [],
            "concept_details": paper['concepts'] if paper['concepts'] else [],

            "embeddings": {
                "full_text_embedding": embedding_list
            } if embedding_list else {}
        }

        return doc

    def index_paper_to_opensearch(self, paper_id: int, doc: Dict[str, Any]) -> bool:
        """OpenSearchì— ë…¼ë¬¸ ë¬¸ì„œ ìƒ‰ì¸"""
        try:
            url = f"{OPENSEARCH_URL}/{INDEX_NAME}/_doc/{paper_id}"
            response = requests.put(url, json=doc, headers={'Content-Type': 'application/json'})

            if response.status_code in [200, 201]:
                return True
            else:
                print(f"âŒ ìƒ‰ì¸ ì‹¤íŒ¨ (Paper ID: {paper_id}): {response.status_code} - {response.text}")
                return False

        except Exception as e:
            print(f"âŒ ìƒ‰ì¸ ì˜¤ë¥˜ (Paper ID: {paper_id}): {e}")
            return False

    def reindex_all_papers(self, batch_size: int = 50):
        """ëª¨ë“  ë…¼ë¬¸ì„ ì¬ìƒ‰ì¸"""
        if not self.connect_postgres():
            return

        # ì´ ë…¼ë¬¸ ìˆ˜ í™•ì¸
        cursor = self.postgres_conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM papers WHERE embedding IS NOT NULL")
        self.total_papers = cursor.fetchone()[0]

        print(f"ğŸ“Š ì´ {self.total_papers}ê°œ ë…¼ë¬¸ì„ ì¬ìƒ‰ì¸í•©ë‹ˆë‹¤...")

        offset = 0
        start_time = time.time()

        while offset < self.total_papers:
            print(f"\nğŸ“¥ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {offset + 1} ~ {min(offset + batch_size, self.total_papers)}")

            # ë°°ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            papers_batch = self.fetch_papers_batch(offset, batch_size)

            if not papers_batch:
                break

            # ê° ë…¼ë¬¸ ìƒ‰ì¸
            batch_success = 0
            for paper in papers_batch:
                paper_id = paper['id']

                try:
                    doc = self.convert_paper_to_opensearch_doc(paper)

                    if self.index_paper_to_opensearch(paper_id, doc):
                        self.indexed_papers += 1
                        batch_success += 1
                        if batch_success % 10 == 0:
                            print(f"  âœ… {batch_success}ê°œ ì™„ë£Œ")
                    else:
                        self.failed_papers += 1

                except Exception as e:
                    print(f"âŒ ë¬¸ì„œ ë³€í™˜ ì‹¤íŒ¨ (Paper ID: {paper_id}): {e}")
                    self.failed_papers += 1

            print(f"ğŸ“Š ë°°ì¹˜ ì™„ë£Œ: ì„±ê³µ {batch_success}/{len(papers_batch)}ê°œ")
            offset += batch_size

            # ì§„í–‰ë¥  ì¶œë ¥
            progress = (self.indexed_papers + self.failed_papers) / self.total_papers * 100
            print(f"ğŸ”„ ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({self.indexed_papers + self.failed_papers}/{self.total_papers})")

        # ìµœì¢… ê²°ê³¼
        elapsed_time = time.time() - start_time
        print(f"\nğŸ‰ ì¬ìƒ‰ì¸ ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µ: {self.indexed_papers}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {self.failed_papers}ê°œ")
        print(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ")

        # OpenSearch ì¸ë±ìŠ¤ í†µê³„ í™•ì¸
        self.check_opensearch_stats()

    def check_opensearch_stats(self):
        """OpenSearch ì¸ë±ìŠ¤ í†µê³„ í™•ì¸"""
        try:
            response = requests.get(f"{OPENSEARCH_URL}/{INDEX_NAME}/_count")
            if response.status_code == 200:
                count_data = response.json()
                print(f"ğŸ“ˆ OpenSearch ì¸ë±ìŠ¤ ë¬¸ì„œ ìˆ˜: {count_data['count']}ê°œ")

            # ì„ë² ë”© ë°ì´í„° í™•ì¸
            search_query = {
                "size": 1,
                "_source": ["title", "embeddings.full_text_embedding"],
                "query": {"exists": {"field": "embeddings.full_text_embedding"}}
            }

            response = requests.post(
                f"{OPENSEARCH_URL}/{INDEX_NAME}/_search",
                json=search_query,
                headers={'Content-Type': 'application/json'}
            )

            if response.status_code == 200:
                search_data = response.json()
                hits = search_data.get('hits', {}).get('hits', [])
                if hits:
                    embedding = hits[0]['_source']['embeddings']['full_text_embedding']
                    print(f"ğŸ“Š ì„ë² ë”© ì°¨ì›: {len(embedding)}ì°¨ì›")
                    print(f"ğŸ“ ì„ë² ë”© ìƒ˜í”Œ: {embedding[:5]}...")
                else:
                    print("âš ï¸ ì„ë² ë”© ë°ì´í„°ê°€ ìˆëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            print(f"âŒ OpenSearch í†µê³„ í™•ì¸ ì‹¤íŒ¨: {e}")

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.postgres_conn:
            self.postgres_conn.close()


if __name__ == "__main__":
    print("ğŸ”„ PostgreSQL â†’ OpenSearch ë…¼ë¬¸ ì¬ìƒ‰ì¸ ì‹œì‘")
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now()}")

    reindexer = PaperReindexer()

    try:
        reindexer.reindex_all_papers(batch_size=20)  # ë°°ì¹˜ í¬ê¸° 20ê°œë¡œ ì„¤ì •
    finally:
        reindexer.close()

    print(f"ğŸ“… ì¢…ë£Œ ì‹œê°„: {datetime.now()}")